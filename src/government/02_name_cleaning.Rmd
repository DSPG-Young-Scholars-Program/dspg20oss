---
title: "02_name_cleaning"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
for (pkg in c("tidyverse", "igraph", "data.table", "R.utils", "RPostgreSQL", "cowplot", "maditr", "gt")) {library(pkg, character.only = TRUE)}

# connect to postgresql to get our data
conn <- dbConnect(drv = PostgreSQL(), 
                  dbname = "sdad", 
                  host = "10.250.124.195", 
                  port = 5432, 
                  user = Sys.getenv("db_userid"), 
                  password = Sys.getenv("db_pwd"))

#github user with emails
gh_extra <- dbGetQuery(conn, "SELECT *
                              FROM gh.ctrs_extra")


# query the users_gh data (table of all github users) 
us_gov_ffrdcs <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_ffrdcs")

# check <- us_gov_ffrdcs %>%
#   group_by(Admin_Name)%>%
#   summarize(N=n())%>%
#   arrange(desc(N))
# write.csv(check, file="gov_admin.csv")
# query the users_gh data (table of all github users) 
us_gov_azindex <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_azindex_clean")

# query the users_gh data (table of all github users) 
us_gov_manual <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_manual")

# query the email domain data
#email_domain_datahub <- dbGetQuery(conn, "SELECT * FROM datahub.domain_names")

# goverment email domains
#https://home.dotgov.gov/data/ (All .gov domains)
#The official public list of .gov domains is updated about every two weeks:
#List of .gov domains - includes all federal, state, interstate, local, and tribal .gov and .fed.us domains.
email_domain_gov <- read_csv("/sfs/qumulo/qhome/zz3hs/oss-data/email_domain_federal_full.csv")%>%
   rename("domain_name" = "Domain Name", "domain_type" ="Domain Type")%>%
  select(-"Security Contact Email", -"City", -"State")%>%
  mutate(domain_name = tolower(domain_name), gov = T)


#email domain country
#https://www.sitepoint.com/complete-list-country-code-top-level-domains/
email_domain_cc <- read.delim("/sfs/qumulo/qhome/zz3hs/oss-data/email_domain_country.txt")
email_domain_cc <- rbind(colnames(email_domain_cc), email_domain_cc)
colnames(email_domain_cc) <- "email_domain"
email_domain_cc$country_code <- "NA" #initialize a column of NA

# identify rows that contain a dot in the string (email domain) 
# shift the row below the previously identified rows to the new column to have matched country email domain with the country name
for (i in (1:nrow(email_domain_cc))){
  cc_i <- email_domain_cc[i,1]
  if(grepl(".", cc_i, fixed = T)){
    email_domain_cc[i, 2] = email_domain_cc[i+1, 1]
  }else{
    email_domain_cc[i, 2] =NA
  }
}
email_domain_cc <- email_domain_cc%>%
  filter(!is.na(country_code))

#remove dot in the email domain
email_domain_cc$email_domain <- str_replace_all(email_domain_cc$email_domain, fixed("."), "") 

# disconnect from postgresql database 
dbDisconnect(conn)
```

# Split github user data into users with email and users with no email
```{r}
#gh_extra_not_na <- gh_extra %>%
#  filter(!is.na(email) | !is.na(company))
#match email adress domain
gh_extra <- gh_extra%>%
  as.data.table() #convert to data table

gh_extra_email <- gh_extra%>%
  filter(!is.na(email))

nrow(gh_extra_email)
nrow(gh_extra_email)/nrow(gh_extra) #27% of github users had email address

##github users don't have emails
gh_extra_no_email <- gh_extra%>%
  filter(is.na(email))%>%
  select(login, email, company, cc_multiple) %>% #prepare for a join
  mutate(is.gov = NA)

nrow(gh_extra_no_email)
```


## Email domain matching
Match email address country domain, gov|fed.us|.mi matching
```{r}
#construct a list of country email domain
email_domain_country_vector <- unlist(email_domain_cc$email_domain)
email_domain_country_pattern <- email_domain_country_vector[1]
for (i in 2:length(email_domain_country_vector)){
  email_domain_country_i<- email_domain_country_vector[i]
  email_domain_country_pattern <- paste(email_domain_country_pattern, email_domain_country_i, sep = "$|")
}
#format into regex search pattern
email_domain_country_pattern <- paste("\\b(?i)(", email_domain_country_pattern, "$)\\b", sep="")

gh_extra_email <- gh_extra_email %>%
  select(login, email, company, cc_multiple)%>% #might add cc_multiple later
  mutate(email_domain_full =  str_extract(email, "(?<=@).*"))%>% #all strings after @
  mutate(email_domain_first = str_extract(email_domain_full, ".*(?=[.])"))%>% #first part of the full domain
  #match goverment email domain (gov, fed.us, mil)
  mutate(is_gov_email_domain = if_else(str_detect(email_domain_full, "\\b(?i)(gov|fed.us|.mil)\\b") == T, T, F)) %>% #note that we are matching any string that contains gov 
  filter(!is.na(email_domain_full))%>%
  #check if the the gh user email domain match the country domain list
  mutate(is.country_email_domain = if_else(str_detect(email_domain_full, email_domain_country_pattern) == T, T, F))%>%
  #extract the country email domain from the full email domain 
  mutate(country_domain = if_else(is.country_email_domain, str_sub(email_domain_full,-2,-1), "NA"))%>%
  #add country name to the dataset by joining with the email domain data
  left_join(email_domain_cc, by = c("country_domain"="email_domain"))%>%
  rename(country_domain_name = country_code)

# email_clean_is_country_email_domain <- gh_extra_email%>%
#   filter(is.country_email_domain) %>%
#   mutate(match_country_code = if_else(cc_multiple ==country_domain, T, F))
# 
# table(is.na(email_clean_is_country_email_domain$cc_multiple)) #26053 github users don't have country code(cc_multiple) but has country related email domain

# check <- email_clean_is_country_email_domain %>%
#   filter(is.na(cc_multiple))%>%
#   group_by(country_domain)%>%
#   summarize(count = n())%>%
#   arrange(desc(count))
# 
# check <- email_clean_is_country_email_domain %>%
#   group_by(email_domain_first)%>%
#   summarize(count = n())%>%
#   arrange(desc(count))
###
table(gh_extra_email$is_gov_email_domain) #726 gh users had .gov (717) or fed.us (only 1), or .mil (only 8) emails


#join the cleaned email from gh with the gov email domain data
gh_extra_email <- gh_extra_email%>%
  left_join(email_domain_gov, by = c("email_domain_full" = "domain_name"))%>%
  mutate(is.usgov = if_else(is.na(domain_type), F, T))%>%
  dplyr::mutate(gov= replace_na(gov, FALSE))

table(gh_extra_email$gov, gh_extra_email$is_gov_email_domain) #430 gh users matched with the email_domain_gov, 296 didn't match (these might be foreign gov)

gh_extra_email <- gh_extra_email %>%
  mutate(is.gov = if_else(is_gov_email_domain == T | gov==T, T, F))%>%
  select(-is_gov_email_domain, -gov)

table(gh_extra_email$is.gov) #consistent with the first match, 726 gh users are gov related

#table of the top gov email domains
# gh_extra_email%>%
#   filter(is.gov)%>%
#   group_by(email_domain_full)%>%
#   summarize(domain_type = unique(domain_type), agency=first(Agency), organization = first(Organization), N=n(),  `percent(%)` = round(100* N/nrow(email_clean), digits= 2))%>%
#   arrange(desc(N))%>%
#   mutate(sum = sum(N))%>%
#   top_n(20, N)%>%
#   select(-sum)%>%
#   gt()

#There are 163 unique gov ending emails. 
length(unique(filter(gh_extra_email, is.gov)$email_domain_full))

gh_extra_email%>%
  group_by(is.gov,is.usgov, is.country_email_domain )%>%
  summarize(N=n())

#did not match either us gov domain or country code
# check<- gh_extra_email%>%
#   filter(is.gov & !is.usgov & !is.country_email_domain)%>%
#   group_by(email_domain_full)%>%
#   summarize(N=n())%>%
#   arrange(desc(N))
gh_extra_email_final <- gh_extra_email%>%
  select(login, email, company, cc_multiple, is.gov)
```

## Full-string matching on identified company names from users previously identified in government sector using email domain
```{r}
gh_extra_company <- rbind(gh_extra_no_email, gh_extra_email_final)

# string <- " us geology"
# str_replace_all(string, "\\b(?i)(u.s.| us|^us)\\b", "united states")   
#  str_replace_all(string, fixed("u.s."), "united states") 

#company cleaning
gh_extra_company <- gh_extra_company%>%
    mutate(company = tolower(company))
gh_extra_company$company <- str_replace_all(gh_extra_company$company, fixed("u.s."), "united states") 

gh_extra_company$company <- str_replace_all(gh_extra_company$company, "\\b(?i)( us|^us)\\b", "united states")  #note here we have "space us" to avoid catch .us email domain in the company  name. Also note that u.s. pattern can't be identified

#remove all non-alphanumeric characters in the company string
gh_extra_company$company <- str_replace_all(gh_extra_company$company,"[^[:alnum:]]", " ") 
#remove leading space induced by the previous step
gh_extra_company$company <- trimws(gh_extra_company$company) 

company_confirm_gov <- gh_extra_company%>%
  filter(is.gov)%>%
  group_by(company)%>%
  summarize(N=n())%>%
  filter(company != "")%>%
  filter(!is.na(company))%>%
  arrange(desc(N))%>%
  filter(N > 1) #cutoff threshold: 1

#full string matching
company_confirm_gov_vector <- unlist(company_confirm_gov$company)


company_confirm_gov_pattern <- company_confirm_gov_vector[1]
for (i in 2:length(company_confirm_gov_vector)){
  company_confirm_gov_i<- company_confirm_gov_vector[i]
  company_confirm_gov_pattern <- paste(company_confirm_gov_pattern, company_confirm_gov_i, sep = "|")
}

company_confirm_gov_pattern <- paste("\\b(?i)(", company_confirm_gov_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(company_match_gov = if_else(str_detect(company, company_confirm_gov_pattern) == T, T, F))%>%
  mutate(company_match_gov= replace_na(company_match_gov, FALSE))

table(filter(gh_extra_company, !is.gov)$company_match_gov)


gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(company_match_gov==T, T, is.gov))

table(gh_extra_company$is.gov)
```

## Bag of words (singleton/bigrams) matching
```{r}
#companies names listed by previously identified users in government sector
company_list <- gh_extra_company%>%
  filter(is.gov)%>%
  select(company)%>%
  filter(!is.na(company))

#bigrams


#singletons
bag_of_words <- as.data.frame(unlist(strsplit(company_list$company, "\\ ")))
colnames(bag_of_words) <- "company"
bag_of_words <- bag_of_words%>%
  group_by(company)%>%
  summarize(N=n())

gh_extra_company <- gh_extra_company%>%
  mutate(bagofword_match_gov = if_else(str_detect(company, "\\b(?i)(national|laboratory|argonne|geological|nasa|survey|alamos|nist|province)\\b") == T, T, F))%>%
  mutate(bagofword_match_gov= replace_na(bagofword_match_gov, FALSE))

table(filter(gh_extra_company, !is.gov)$bagofword_match_gov)


gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(bagofword_match_gov==T, T, is.gov))

table(gh_extra_company$is.gov)
```

## U.S. Government Department/Agency name matching
```{r}
#I.azindex
#I.1 agency
az_list_agency <- distinct(us_gov_azindex, agency) %>% 
  rename(institution = agency)%>%
  mutate(dataset = "azindex_agency")

##I.2gov agency
az_list_gov_agency <- distinct(us_gov_azindex, gov_agency) %>%
  rename(institution = gov_agency)%>%
  mutate(dataset = "azindex_gov_agency")

##I.3gov branch
az_list_gov_branch <- distinct(us_gov_azindex, gov_branch)%>%
  rename(institution = gov_branch)%>%
  mutate(dataset = "azindex_gov_branch")%>%
  filter(institution != "None")

##I.4 child agency
az_list_child_agency <- distinct(us_gov_azindex, child_agency)%>%
  rename(institution = child_agency)%>%
  mutate(dataset = "azindex_child_agency")


#II. ffrdc
##II.1 FFRDC
ffrdc_list <- distinct(us_gov_ffrdcs, FFRDC_Name)  %>% 
  rename(institution = FFRDC_Name)%>%
  mutate(dataset = "ffrdc" )

##II.2 agency
ffrdc_list_agency <- us_gov_ffrdcs%>%
  select(Agency, Agency2, Agency3)%>%
  gather("agency_type", "agency_name")%>%
  filter(!is.na(agency_name))%>%
  distinct(agency_name) %>% 
  rename(institution = agency_name)%>%
  mutate(dataset = "ffrdc_agency")

##II.2 sub agency
ffrdc_list_sub_agency <- us_gov_ffrdcs%>%
  select(FFRDC_Name, Sub_Agency, Sub_Agency2, Sub_Agency3)%>%
  gather("agency_type", "agency_name")%>%
  filter(!is.na(agency_name))%>%
  distinct(agency_name)%>% 
  rename(institution = agency_name)%>%
  mutate(dataset = "ffrdc_sub_agency" )

#III.usman
usman_list <- us_gov_manual%>%
  distinct( AgencyName)  %>% 
  rename(institution = AgencyName)%>%
  mutate(dataset = "usman")

all_lists <- rbind(az_list_agency, az_list_gov_agency, az_list_gov_branch, az_list_child_agency, ffrdc_list_agency, ffrdc_list_sub_agency, usman_list)
all_lists <- distinct(all_lists, institution, .keep_all = TRUE)

all_lists_clean <- all_lists %>% 
  arrange(institution)%>% 
   filter(!is.na(institution))%>%
   mutate(institution = tolower(institution))%>%
   mutate(institution2 = str_replace_all(institution , fixed("u.s."), "united states"))%>%
   gather("institution_type",  "institution_name", -dataset)%>%
   select(-institution_type)%>%
   distinct(institution_name, .keep_all=T)%>%
   rename(institution = institution_name)


all_lists_clean <- as.data.frame(unlist(strsplit(all_lists_clean$institution, "\\(")))
names(all_lists_clean) <- "institution"
all_lists_clean$institution <- str_replace_all(all_lists_clean$institution , fixed(")"), "") 

all_lists_clean <- all_lists_clean%>%
  mutate(num_alp = str_length(institution))%>%
  filter(num_alp >2)

###Unlist
gov_name_vector <- unlist(all_lists_clean$institution)

gov_name_pattern <- gov_name_vector[1]
for (i in 2:length(gov_name_vector)){
  gov_name_i<- gov_name_vector[i]
  gov_name_pattern <- paste(gov_name_pattern, gov_name_i, sep = "|")
}

gov_name_pattern <- paste("\\b(?i)(", gov_name_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(gov_name_match_company = if_else(str_detect(company, gov_name_pattern) == T, T, F))%>%
  mutate(gov_name_match_company= replace_na(gov_name_match_company, FALSE))


nrow(filter(gh_extra_company, !is.gov, gov_name_match_company == T))

check <- filter(gh_extra_company, !is.gov, gov_name_match_company == T)


gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(gov_name_match_company==T, T, is.gov))

table(gh_extra_company$is.gov)
```

## Catch the fish--final matching
```{r}
####final step
gh_extra_company <- gh_extra_company%>%
  mutate(is.gov.extra = if_else(str_detect(company, "\\b(?i)(gov|government|bureau|federalhomeland security|fbi|cia|census|us army|u.s. army|united state army|usarmy)\\b") == T, T, F))%>%
  mutate(is.gov.extra= replace_na(is.gov.extra, FALSE))

check <- filter(gh_extra_company, !is.gov, is.gov.extra == T)

nrow(filter(gh_extra_company, !is.gov, is.gov.extra == T))

gh_extra_company <- gh_extra_company%>%
    mutate(is.gov = if_else(is.gov.extra==T, T, is.gov))

table(gh_extra_company$is.gov)
```

#check internaitonal or domestic
```{r}
check <- gh_extra_company%>%
  filter(is.gov)
table(is.na(check$domain_type))
```


# 
```{r}
organization_counts <- gh_extra %>% 
  drop_na(company) %>% 
  mutate(organization = str_to_lower(company)) %>% 
  mutate(organization = str_trim(organization)) %>% 
  mutate(organization = ifelse(test = str_detect(string = organization, 
                              pattern = "\\b(?i)(freelancer|freelance|freelancing|freelancers|freelances|self|personal|home|private|individual|myself|me|independent|independent contractor|contractor|private|household|house|home|my house|jobless|looking for a job|looking for job|seeking employment|seeking|actively seeking employment|seeking opportunities|seeking internship|seeking work)\\b"), 
                              yes = "household", no = organization)) %>%
  mutate(organization = ifelse(test = str_detect(string = organization, 
                              pattern = "\\b(?i)(n/a|none|null|no|na)\\b"),      
                              yes = "none/null", no = organization)) %>% 
  group_by(organization) %>% count() %>% arrange(-n)
```

