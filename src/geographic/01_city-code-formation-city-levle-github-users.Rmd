---
title: "01 City Code Formation-And Overview of City-levle Githubu Users"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r loading data, message=FALSE, warning=FALSE, include=FALSE}
rm(list = ls())

# load packages 
for (pkg in c("tidyverse", "igraph", "visNetwork", "data.table", "R.utils", "RPostgreSQL", "cowplot", "maditr", "stringr", "stringi", "mosaic", "sf", "raster", "dplyr", "spData", "spDataLarge", "tmap", "leaflet", "mapview", "ggplot2", "shiny", "maps", "plotly")) {
  library(pkg, character.only = TRUE)
}


# connect to postgresql to get our data
conn <- dbConnect(drv = PostgreSQL(), 
                  dbname = "sdad", 
                  host = "10.250.124.195", 
                  port = 5432, 
                  user = Sys.getenv("db_userid"), 
                  password = Sys.getenv("db_pwd"))

# query the users_gh data from github data 
users_gh <- dbGetQuery(conn, "SELECT login, created_at, city, state, country_code, location, long, lat
                              FROM gh.ctrs_raw")

# cities_maxmind <- dbGetQuery(conn, 
# "SELECT *
#   FROM maxmind.world_cities"
# )

# too large to read in the raw commit data. Will crash R
# commits <- dbGetQuery(conn,
#                       "SELECT *
#                       FROM gh.commits_raw")

# gh_extra <- dbGetQuery(conn, "SELECT *
#                               FROM gh.ctrs_extra")

# disconnect from postgresql database 
dbDisconnect(conn)
```


```{r eda, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

user_us <- users_gh%>%
  filter(country_code == "us ")

# 1. github user
# check: users who don't have any of city, state, location, long, lat, don't have country code
# user_geo_na <- users_gh %>%
#   filter(is.na(state))%>%
#   filter(is.na(city))%>%
#   filter(is.na(location))%>%
#   filter(is.na(long), is.na(lat))
# table(is.na(user_geo_na$country_code)) #all users have country code

# filter out users with no country/city
perc_missing <- sum(is.na(users_gh$country_code) | is.na(users_gh$city))/nrow(users_gh) #percent missing
sample_size <- nrow(users_gh)- sum(is.na(users_gh$country_code) | is.na(users_gh$city)) #number of gh users after exlucding missing country code or city

# some users who are missing country code have cities, but cities might not be reliable
users_gh_countrycode_na <- users_gh%>%
  filter(is.na(country_code))

# check: users created year
# class(users_gh$created_at) 
# users_gh_clean <- users_gh_clean %>%
#   mutate(created_year = substring(created_at, 1,4)) #extract year from the date
# table(users_gh_clean$created_year)
```

# Country Level Github Users
```{r country level, echo=FALSE}
# summarize ttl number of users in each country
country_by_ttl_user <- users_gh%>%
  filter(!is.na(country_code))%>%
  group_by(country_code)%>%
  dplyr::summarize(ttl_users = n())%>%
  arrange(desc(ttl_users)) %>%
  top_n(n= 10, wt = ttl_users)

country_by_ttl_user$country_code <- factor(country_by_ttl_user$country_code, levels = country_by_ttl_user$country_code[order(country_by_ttl_user$ttl_users)])

ggplot(country_by_ttl_user, aes(x = country_code, y = ttl_users)) +
  geom_point() +
  labs(title = "Countries where Github users are located", x = "country", y = "total number of users") +
  theme_bw() 
```



# City code formation
We exclude users who did not provide either country code or city information. (`r perc_missing`% missing), which leaves us `r sample_size` samples in the dataset. Note that country code is extracted from country, city, loaction, and longitude and latitude. Country code is missing if the user did not provide any of these information. Since we are interested in users at the city level, if we are missing city information, we could not extract a unique city.    

We formed city code in the following steps:   

First, we want to differentiate cities from different countries. We form a new variable "city_code", which is a concactinated form of country code and city. Since there could be multiples cities with the same name in different countries, "city_code" can be used to differentiate cities from from different countries.

Next, we want to differentiate cities within a country. Although we have state variable, but we decide no to use this variable due to the inaccurate report. We decide to use longitude and latitude to differentiate cities in different areas in a country. However, longtitude and latitude could vary from a small digit even though they indicate one city. We decide to group cities together if their long & lat deviate within a sum of 2 degrees. 

The final "city_code" is a concactinated form of:
  -country code (generated)
  -city
  -latitude (round to a whole number)
  -longitude (round to a whole number)

```{r city code cleaning function, message=FALSE, warning=FALSE, include=FALSE}
CapStr <- function(y) {
  c <- strsplit(y, " ")[[1]]
  paste(toupper(substring(c, 1,1)), substring(c, 2),
      sep="", collapse=" ")
}

cleancity <- function(df = users_gh){
  #first step: form city_code variable, a concactinated form of country code and city name
  df <-  df%>%
    filter(!is.na(country_code) & !is.na(city))%>% #exclude missing values
    mutate(city = str_to_lower(city)) %>% #lowercase all city names
    mutate(city_code  = paste(country_code, city, sep="_"))
  
  df$city_code <- str_replace_all(df$city_code, fixed(" "), "") #remove space in the city code string

 #second step: form user_geo_location, a concactinated form of rounded longitude and latitude
 df <-  df%>%
    mutate(user_long = long, user_lat = lat, user_long_round = round(long,digits=0), user_lat_round = round(lat, digits=0), user_geo_location = paste(user_lat_round, user_long_round, sep="."))
 
 df_sum <- df %>%
    group_by(city_code, user_geo_location) %>%
    dplyr::summarize( ttl_users = n(), user_lat = mean(user_lat), user_long = mean(user_long), user_lat_round= mean(user_lat_round), user_long_round = mean(user_long_round))%>%
    arrange(desc(ttl_users))
 
# problem: filter function is not working!!! 
# class(df)
# dim(df)
# df <- as_tibble(df)
# 
#  df_us <- df%>%
#    dplyr::filter(country_code == "us")

  # create an indicator for each row whether the city_code (country+city name) is duplicated
  df_sum<- df_sum%>%
    group_by(city_code)%>%
    mutate(n_city_code=n(), duplicate = if_else(n_city_code > 1, T,F))
  
  # data with duplicated city code
  #12% of city_code do not have duplicates (N=1515)
  #nrow(df_dup)
  #nrow(df_dup)/nrow(df)
  df_dup <- df_sum%>%
    filter(duplicate == T)
  
  # data with no duplicated city code
  #88% of city_code do not have duplicates (N=11537)
  #nrow(df_no_dup)
  #nrow(df_no_dup)/nrow(df)
  df_no_dup <- df_sum%>%
    filter(duplicate == F)%>%
    select(city_code, user_geo_location)
  
  # duplicated city_code, in vector form
  city_code_dup <- unique(df_dup$city_code)
  
  df_update_geocode <- c()
  df_analysis_citycode <- c()
#  i =  grep("fr_paris", city_code_dup)  #check for one city, get the index of the city you are interested in checking in the city_code_dup vector
  
  for ( i in 1: length(city_code_dup)){
    city_code_i = city_code_dup[i]
    message("city #", i, ":", city_code_i)
    df_dup_i <- df_dup %>%
      filter(city_code == city_code_i)%>%
      arrange(desc(ttl_users))
    
    #identify the geo location where has the most users, treat this geo location as benchmark
    actual_long <-unlist(df_dup_i[1, long_col <- grep("user_long_round", colnames(df_dup_i)) ])
    actual_lat <-  unlist(df_dup_i[1,  lat_col <- grep("user_lat_round", colnames(df_dup_i))])
        
    # 1 degree difference = 1.5 hrs drive
    # 2 degrees difference = 2 hrs drive
    df_dup_i_check <- df_dup_i %>%
      mutate(long_diff = abs(actual_long - user_long), lat_diff = abs(actual_lat - user_lat), diff_sum = long_diff+ lat_diff)%>%
    mutate(combine = ifelse(diff_sum <= 2 , T, F))%>%
      mutate(rowindex = 1:nrow(df_dup_i), benchmark = if_else(rowindex== 1, T,F))
    
    df_dup_i_check<- df_dup_i_check%>%
      select(-rowindex)
    
    df_analysis_citycode <- rbind(df_analysis_citycode, df_dup_i_check)
       
    ######### group cities within 2 degrees of the benchmarked city together
    df_cb <- df_dup_i_check%>%
      filter(combine == T)
    
    if(nrow(df_cb) > 1){
      message ("Resembling geocode identified, group ", nrow(df_cb), " geocode(s) for ", "city #", i, ":", city_code_i)
     geo_location_new  = as.vector(df_cb$user_geo_location)[1]
     
     df_cb <- df_cb%>%
       select(city_code, user_geo_location)%>%
       mutate(user_geo_location_new = geo_location_new)
      
    }else{
      message("Did not identify resembling geocode.")
      city_code = as.vector(df_cb$city_code)
      user_geo_location = as.vector(df_cb$user_geo_location)
      user_geo_location_new = as.vector(df_cb$user_geo_location)
      vector_update_geocode <- data.frame(city_code,user_geo_location, user_geo_location_new, stringsAsFactors=FALSE)
      
      df_cb <- df_cb %>%
        select(city_code, user_geo_location)%>%
        mutate(user_geo_location_new = user_geo_location)
    }
   

    df_nocb <- df_dup_i_check%>%
      filter(combine == F)%>%
      select(city_code, user_geo_location)%>%
      mutate(user_geo_location_new = user_geo_location)
    
    update_geocode <- rbind(df_cb, df_nocb)
    
    df_update_geocode <- rbind(df_update_geocode, update_geocode)

    
    # df_output <- df_output %>%
    #    mutate(city_code = paste(city_code, user_lat_round, user_long_round, sep = "_"))
    # 
    # citycode_split <- strsplit(df_output$city_code, "_")
    # 
    #  df_output <- df_output %>%
    #    mutate(country_code = citycode_split[[1]][1], 
    #           city = citycode_split[[1]][2])
    # 
    }
    
  #original dataset, user level
  df <- df%>%
    mutate(city_code = paste(city_code, user_geo_location, sep = "_"))
  
  #citycode that have duplicates
  df_dup <- df_update_geocode%>%
    mutate(city_code_rep = city_code)%>%
    mutate(city_code = paste(city_code, user_geo_location, sep = "_"))%>%
    mutate(city_code_new = paste(city_code_rep, user_geo_location_new, sep = "_"))%>%
    select(city_code, city_code_new)
  
  #citycode that does not have duplicates
  df_no_dup <- df_no_dup%>%
   mutate(city_code = paste(city_code, user_geo_location, sep = "_"), city_code_new = city_code)%>%
    select(-user_geo_location)
  
  df_update_geocode_all <- rbind(df_dup, df_no_dup)
    
  df_cleaned <- left_join(df, df_update_geocode_all, by="city_code")

 df_cleaned$city <- sapply(df_cleaned$city, CapStr)

 ls_citycode  <- list()
 ls_citycode[[1]] <-  df_analysis_citycode
 ls_citycode[[2]]  <- df_cleaned
 
 names(ls_citycode) <- c("analysis_df", "cleaned_df")
 
 return(ls_citycode)
}
```


# Clean citycode
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
ls_cleancity <- cleancity(users_gh)
```


# city code analysis
```{r city code and visualization, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
### analysis
cleancitycode_analysis <- ls_cleancity$analysis_df

city_non_benchmark <- cleancitycode_analysis%>%
  filter(benchmark == F)
#each dot represents a geographic location that has multiple longitude and latitude
ggplot(city_non_benchmark, aes(x = diff_sum, y = ttl_users)) +
  geom_point(size = 0.5)  + 
  aes(colour = combine) + 
  theme(legend.position = "right") + 
  labs(title = "")

#distribution of the sum of differences in longitude and latitude at each of the geographic location comparing to the benchmarked city.
ggplot(city_non_benchmark, aes(x = diff_sum)) +
  geom_histogram(binwidth = 3.9) + 
  labs(title="Distribution of the distance between each geographic location with the benchark city",
        x ="sum of difference in longitude and latitude")+
  theme(plot.title = element_text(size=9))

# 20% of 
table(city_non_benchmark$combine)
```

### clean citycode visualization
```{r}
city_clean_final <- ls_cleancity$cleaned_df

#aggregate by country
city_clean_final_aggregate_country <- city_clean_final%>%
  group_by(country_code)%>%
  summarize(ttl_users = n())
city_clean_final_aggregate_country$country_code <- gsub(" ", "", city_clean_final_aggregate_country$country_code, fixed = TRUE)

#aggregate by city
city_clean_final_aggregate <- city_clean_final%>%
  group_by(city_code_new)%>%
  summarize(ttl_users = n(), lat = mean(lat), long = mean(long))%>%
  arrange(desc(ttl_users))%>%
  mutate(country = substr(city_code_new, 1,2))

city_clean_final_aggregate$city <- str_extract(city_clean_final_aggregate$city_code_new,"_(.*)_") 

city_clean_final_aggregate$city <- gsub("_", "", city_clean_final_aggregate$city, fixed = TRUE)

city_clean_final_aggregate$city<- sapply(city_clean_final_aggregate$city,CapStr)

#####################

city_clean_final_top <- city_clean_final_aggregate %>%
  top_n(n= 10, wt = ttl_users)%>%
  mutate(country_code = substr(city_code_new, 1,2))
 
 citycode_split <- strsplit(city_clean_final_top$city_code_new, "_")

 
 city_names <- c()
 for(i in 1:10){
   city_name <- citycode_split[[i]][2]
   city_names <- c(city_names, city_name)
 }

  city_clean_final_top <- city_clean_final_top%>%
    mutate(city = city_names)
  
city_clean_final_top$city <- factor(city_clean_final_top$city, levels = city_clean_final_top$city[order(city_clean_final_top$ttl_users)])


ggplot(city_clean_final_top, aes(x = city, y = ttl_users)) +
  geom_point()  +
  aes(colour = country_code)+
  theme(legend.position = "right") + 
  labs(title = "Cities where Github users are located", x = "city", y = "total number of users") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

###
leaflet()%>%
  addTiles()%>%
  addProviderTiles("OpenStreetMap.Mapnik")

names(providers)
names(providers)[str_detect(names(providers), "CartoDB")]

summary(city_clean_final_aggregate$ttl_users)

#color 
city_clean_final_aggregate_top <- city_clean_final_aggregate%>%
  filter(ttl_users > 1)
library(RColorBrewer)
library(leaflet.extras)

pal <- colorNumeric(palette = "Blues" , domain = c(min(city_clean_final_aggregate_top$ttl_users): max(city_clean_final_aggregate_top$ttl_users)), reverse = F)

#ttl user indicated by color
city_clean_final_aggregate_top %>%
  leaflet()%>%
  addTiles()%>%
  addSearchOSM()%>%
  addReverseSearchOSM()%>%
  clearMarkers()%>%
  addResetMapButton()%>%
  addCircleMarkers(
    lng = ~long , 
    lat = ~lat, 
    label = ~ paste(city, country, sep = ', \n'),
    radius = 0.1, 
    color = ~pal(ttl_users))%>%
  addLegend(title = "Number of Github Users", 
            pal = pal, 
            values = c(100: 15927), 
            position = "bottomright", 
            opacity = 0.5)
  

#ttl user indicated by size
city_clean_final_aggregate_top %>%
  leaflet()%>%
  addTiles()%>%
  addSearchOSM()%>%
  addReverseSearchOSM()%>%
  clearMarkers()%>%
  addResetMapButton()%>%
  addCircleMarkers(
    lng = ~long , 
    lat = ~lat, 
    label = ~ paste(city, country, sep = ', \n'),
    radius = ~ttl_users^(1/3), 
    color = "green")
    
 # addMarkers(lng =city_clean_final_top$long , lat = city_clean_final_top$lat)



```


# Examine city code quality by comparing with user input
```{r}
us_greenville <- city_clean_final%>%
  filter(country_code == "us ")%>%
  filter(city == "greenville")%>%
  group_by(city_code, state,location)%>%
  summarize(N=n())


us_sanfrancisco<- city_clean_final%>%
  filter(country_code == "us ")%>%
  filter(city == "san francisco")%>%
  group_by(state,  long, lat)%>%
  summarize( N=n())


us_sanfrancisco_location<- city_clean_final%>%
  filter(country_code == "us ")%>%
  filter(city == "san francisco")%>%
  group_by(state, long, lat,  location)%>%
  summarize( N=n())


```

# compare with maxmind global city

```{r}
#start with us

# world cities data
cities_maxmind <- cities_maxmind%>%
 # filter(Country == "us")%>%
  mutate(long = round(Longitude, digits=0), lat = round(Latitude, digits=0))%>%
  mutate(city_code  = paste(Country, City, sep="_"), geo_location = paste( lat, long, sep= "."))%>%
  mutate(city_code = paste(city_code, geo_location, sep="_"))%>%
  select(city_code, Population,City,Region)

ghuser_cross_maxmind <- left_join(city_clean_final, cities_maxmind, by = c("city_code_new" = "city_code"))
```



# Visualization
```{r}
# sf
#create shape file
gh_suer_sf <- st_as_sf(city_clean_final_aggregate, coords = c("lat", "long"))
summary(gh_suer_sf)

###########
prj <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")

coords <- city_clean_final_aggregate %>% select(long, lat)

city_clean_final_aggregate_pt <- SpatialPointsDataFrame(coords = coords, data = city_clean_final_aggregate, proj4string = prj)
class(city_clean_final_aggregate_pt)

proj4string(city_clean_final_aggregate)


plot(city_clean_final_aggregate_pt)

#############

map_nz = tm_shape(gh_suer_sf) + tm_polygons()

world_map <- map_data("world")

library(ggrepel)
library(plotly)

#static map
ggplot() +
  geom_polygon(data = city_clean_final, aes(x=long, y = lat, group = group), fill="grey", alpha=0.2) +
  geom_point( data= city_clean_final, aes(x=user_long, y=user_lat, alpha=ttl_users)) +
  geom_text_repel( data= city_clean_final %>% arrange(ttl_users) %>% tail(10), aes(x=user_long, y=user_lat, label=city), size=4) +
  geom_point( data=city_clean_final %>% arrange(ttl_users) %>% tail(10), aes(x=user_long, y=user_lat), color="red", size=4) +
  theme_void() + 
  coord_map() +
  theme(legend.position="none")



#interactive map
#8.4 interactive maps
world <- world%>%
  mutate(iso_a2 = str_to_lower(iso_a2))
world_gh = left_join(world, city_clean_final_aggregate_country, by = c("iso_a2" = "country_code"))

tm_shape(city_clean_final_aggregate_pt) +
  tm_polygons(col = "ttl_users")+
  tm_basemap(server = "OpenTopoMap")+ 
  tm_legend(outside = TRUE)

class(map_world)


```


```{r top users, eval=FALSE, include=FALSE}
# topuser <- commits%>%
#   group_by(login)%>%
#   dplyr::summarize(ttl_commit = n(), .groups = "keep")%>%
#   arrange(desc(ttl_commit))%>%
#   top_n(n= 10)
```


