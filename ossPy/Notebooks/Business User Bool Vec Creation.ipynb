{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of our overarching strategy for assigning users to specific sectors, we need to be able to assign users to business as well.  Given the specifics of our source dataset (GHTorrent), we can reasonably assume that the more frequently that a company name appears, the more \"authoratative\" (reflective of a consensus) of a representation of that company name it is.  Once we've removed the user entries that correspond to the non-business sectors, we can be reasonably confident in mapping users whose worplace affiliation listing is shared with some critical threshold of other users (i.e. 5) to the business sector.\n",
    "\n",
    "Lets begin by obtaining the raw user data, as well as the user mappings for the acadmic and government sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "#assuming you're starting this notebook from it's source directory,\n",
    "#this will get us to the directory containing the ossPyFuncs library\n",
    "import ossPyFuncs\n",
    "\n",
    "#obtain the raw GHTorrent data\n",
    "postgreSql_selectQuery=\"SELECT login, company FROM gh.ctrs_raw ;\"\n",
    "fullData=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#perform sql query for academic entries\n",
    "postgreSql_selectQuery=\"SELECT login, company_cleaned, is_academic FROM gh.sna_ctr_academic ;\"\n",
    "academicCleaned=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#perform sql qery for government entries\n",
    "postgreSql_selectQuery=\"SELECT login, is_gov FROM gh.sna_ctr_gov ;\"\n",
    "govData=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#add nonprofit here and in the next code block if desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained those pre-exisitng user mappings, we need to join them into one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the academic into the raw table\n",
    "joinedData1=fullData.set_index('login').join(academicCleaned.set_index('login'))\n",
    "\n",
    "#join the government table into the raw/academic table\n",
    "joinedData2=joinedData1.join(govData.set_index('login'))\n",
    "\n",
    "#reset the the indexes\n",
    "joinedAndReset=joinedData2.reset_index()\n",
    "\n",
    "#it seems that the sql query pulls in boolean falses as NANs, which is not want we want for a boolean vector\n",
    "#as such, we replace the NANs in the relevant columns with false\n",
    "naReplaced=joinedAndReset[['is_gov','is_academic']].fillna(value=False)\n",
    "\n",
    "#take those NAN replaced columns and reinsert them\n",
    "fixedDataframe=joinedAndReset.assign(is_gov=naReplaced['is_gov'],is_academic=naReplaced['is_academic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform a full sectoring we also need the information for household and null values.  Lets obtain those now from our source keylists.  After that, we'll determine which users have yet to be mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#get the directory structure using the ossPyFuncs library as the reference point\n",
    "currentDir=os.path.dirname('ossPyFuncs.py')\n",
    "\n",
    "#obtain the household list from the keyfile directory, and make a bool column for it\n",
    "houseHoldList=pd.read_csv(os.path.join(currentDir,'keyFiles/individualKeys.csv'),quotechar=\"'\",header=None)\n",
    "withHouseholdColumn=ossPyFuncs.addBooleanColumnFromCriteria(fixedDataframe,houseHoldList,'household')\n",
    "\n",
    "#obtain the null list from the keyfile directory, and make a bool column for it\n",
    "noneList=pd.read_csv(os.path.join(currentDir,'keyFiles/nullKeys.csv'),quotechar=\"'\",header=None)\n",
    "withNoneColumn=ossPyFuncs.addBooleanColumnFromCriteria(withHouseholdColumn,noneList,'null')\n",
    "\n",
    "#generate a bool column for all users that have been mapped, these will be excluded from our business count\n",
    "alreadyAssigned=withNoneColumn[['is_gov','is_academic','household','null']].any(axis=1)\n",
    "\n",
    "#extract those users which are not assigned\n",
    "onlyUnassignedFrame=fixedDataframe.loc[~alreadyAssigned]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have derived the list of users which have yet to be assigned, lets clean their input in the company column, in preperation for subsequent processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#construct path to legal entity list and erase them\n",
    "LElist=pd.read_csv(os.path.join(currentDir,'keyFiles/curatedLegalEntitesRaw.csv'),quotechar=\"'\",header=None)\n",
    "LEoutput, LEeraseList=ossPyFuncs.eraseFromColumn(onlyUnassignedFrame['company'],LElist)\n",
    "\n",
    "#construct path to legal symbol list and erase them\n",
    "symbollist=pd.read_csv(os.path.join(currentDir,'keyFiles/symbolRemove.csv'),quotechar=\"'\",header=None)\n",
    "Symboloutput, symbolEraseList=ossPyFuncs.eraseFromColumn(LEoutput,symbollist)\n",
    "#construct path to legal symbol list and erase them\n",
    "domainsList=pd.read_csv(os.path.join(currentDir,'keyFiles/curatedDomains.csv'),quotechar=\"'\",header=None)\n",
    "domiansOutput, domainsEraseList=ossPyFuncs.eraseFromColumn(Symboloutput,domainsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll do this in a different cell, as the previous one can take quite a while\n",
    "\n",
    "#remap all of the space, case, and symbol variants to their most common form\n",
    "fixedList=ossPyFuncs.spaceSymbolRemap(pd.DataFrame(domiansOutput))\n",
    "\n",
    "#report the number of changes made\n",
    "print(str(np.sum(fixedReport['changeNum'])),' space, case and symbol variations entries remapped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fully cleaned and remapped the data (and in doing so, collapsed redundant entries in to one another) we can now apply our heuristic count.  Specifically, given that we have removed all entries which would be associated with governmental, academic, and independent (household) users (and removed null entries), it seems reasonable to assume that entries which have multiple users listing them are businesses.  This inference is based on our exhausting any other workplace affiliations that a person might express.\n",
    "\n",
    "However, we have to apply a (somewhat arbitrary) cutoff when we decide the minimum number of users which have to list the same workplace in order for us to assume it reflects a valid business.  We'll begin with 5, but the code can be changed as one sees fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the threshold, change if you'd like\n",
    "threshold=5\n",
    "\n",
    "#here we're going to obtain a frequency count of the workplace listings.  However, in preperation for a step we\n",
    "#will be taking later we'll also use this opportunity to obtain the user mappings for each unique company.  In\n",
    "#this way we can determine which users are associated with a workplace listing that meets the threshold criterion\n",
    "#that we established at the start of this cell.\n",
    "sortedInputColumn, sortedTableUniqueFullNameCounts=ossPyFuncs.uniquePandasIndexMapping(fixedList)\n",
    "\n",
    "#+1 because we are using greater than or equal to\n",
    "#we'll also be using this vector to obtain our user remapping\n",
    "aboveThresholdBoolVec=sortedTableUniqueFullNameCounts['count'].ge(threshold+1)\n",
    "\n",
    "totalUsersAboveThreshold=np.sum(sortedTableUniqueFullNameCounts['count'].loc[aboveThresholdBoolVec])\n",
    "\n",
    "print(str(totalUsersAboveThreshold)+ ' users users assumed to be business sector, with ' str(threshold) ' or more other users with the same listing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the raw count of the users meeting this criteria, we can also obtain a boolean vector that indicates which users are associated with these presumed businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#may need to resort this in order to get it to line up with origional\n",
    "subjectIndexArray=sortedTableUniqueFullNameCounts['inputIndexMapping'].loc[aboveThresholdBoolVec].array()\n",
    "\n",
    "fullData['is_business']=False\n",
    "#somehow need to flatten, use np.ravel for this \n",
    "fullData['is_business'].loc[np.ravel[(subjectIndexArray)]=True\n",
    "                            \n",
    "#this modified \"fullData\" object is now the desired ouput.  It can be joined with the entries in withNoneColumn\n",
    "#if one wishes for a complete output data object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
