{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous chapters we (1) assessed our ability to map the raw GHTorrent data on to sectors using some given lists [see chapter \"Overview of raw GHTorrent professional affiliation data.ipynb\"] and (2) looked at the data itself and conisidered/implemented some cleaning heuristics [see chapters \"Difflib demo.ipynb\" and \"Company Cleaning Narritive.ipynb\"].  Now that we've done all this work, we actually need to see if these strategies have accomplished anything.  Ideally, what we have been doing is removing the \"noise\" from our data such that the entires in the raw data represent a more \"unified\" expression of the same affilliations, and thus better map on to the target entity lists.  The result of this would be a greater number of entries being mapped to each sector.  Alternatively, another method for mapping more entries to those sectors would be to improve/augment our per-sector lists of entities.  We'll set that option aside for now and proceed by evaluating the results of our cleaning efforts using largely the same approach as we did in the \"raw overview\" chapter.\n",
    "\n",
    "This time we begin by loading the cleaned set,rather than pulling from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nearform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mbari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>scality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>crom microsystems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>oohology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>object rocket at rackspace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>rackspace hosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>thinkphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>reaktor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>arkency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>juliand digital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>primerai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>karlsruhe institute of technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>freelance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>inextensodigital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>bakkenbaeck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              company\n",
       "0                            nearform\n",
       "1                             answers\n",
       "2                               mbari\n",
       "3                             scality\n",
       "4                   crom microsystems\n",
       "5                            oohology\n",
       "6                               apple\n",
       "7          object rocket at rackspace\n",
       "8                   rackspace hosting\n",
       "9                            thinkphp\n",
       "10                            reaktor\n",
       "11                            arkency\n",
       "12                    juliand digital\n",
       "13                           primerai\n",
       "14  karlsruhe institute of technology\n",
       "15                          freelance\n",
       "16                   inextensodigital\n",
       "17                        bakkenbaeck\n",
       "18                             google\n",
       "19                             github"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this code guarentees you can impor the ossPyFuncs library\n",
    "import subprocess\n",
    "import os\n",
    "#get top directory path of the current git repository, under the presumption that\n",
    "#you're in the dspg20oss repo.\n",
    "gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()\n",
    "#move to the osspy directory, assuming the directory structure has remained the  same\n",
    "os.chdir(os.path.join(gitRepoPath, 'ossPy'))\n",
    "#import the osspy library\n",
    "import ossPyFuncs\n",
    "import pandas as pd\n",
    "\n",
    "currentDir=os.path.dirname('ossPyFuncs.py')\n",
    "#read in the file\n",
    "cleanedInput=pd.read_csv(os.path.join(currentDir,'PackageOuts/rawCleanNoNA.csv'))\n",
    "companyColumn=pd.DataFrame(cleanedInput['company'])\n",
    "companyColumn.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see that slightly more than 80% of users have not entered anything into the company column.  This doesn't bode particularly well for our attempt to begin mapping sectors, but let's investigate what we do have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin  with the list for the household/individual category.  We'll begin by loading up our criteria list and taking a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(?i)^self$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(?i)^personal$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(?i)^home$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(?i)^private$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(?i)^individual$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(?i)^myself$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>(?i)^me$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>(?i)^house$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(?i)^independent$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(?i)independent contractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>(?i)^consultant$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>(?i)freelancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>(?i)freelance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>(?i)freelancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>(?i)self-employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>(?i)my home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>(?i)me, myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>(?i)me myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>(?i)household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>(?i)my house</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "0                   (?i)^self$\n",
       "1               (?i)^personal$\n",
       "2                   (?i)^home$\n",
       "3                (?i)^private$\n",
       "4             (?i)^individual$\n",
       "5                 (?i)^myself$\n",
       "6                     (?i)^me$\n",
       "7                  (?i)^house$\n",
       "8            (?i)^independent$\n",
       "9   (?i)independent contractor\n",
       "10            (?i)^consultant$\n",
       "11              (?i)freelancer\n",
       "12               (?i)freelance\n",
       "13             (?i)freelancing\n",
       "14           (?i)self-employed\n",
       "15                 (?i)my home\n",
       "16              (?i)me, myself\n",
       "17               (?i)me myself\n",
       "18               (?i)household\n",
       "19                (?i)my house"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get path to local github directory for the ossPy function set, use that as a marker to find other files\n",
    "currentDir=os.path.dirname('ossPyFuncs.py')\n",
    "#read in the file\n",
    "householdTermList=pd.read_csv(os.path.join(currentDir,'keyFiles/individualKeys.csv'),quotechar=\"'\",header=None)\n",
    "#look at some of the items  \n",
    "householdTermList.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these are all sql queries for strings which are (we assume) associated with individuals who are engaging in home innovation with open source.  Lets see how many of the individuals from the GHTorrent database this reflects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4819 household innovators found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "freelancer                 990\n",
       "freelance                  949\n",
       "home                       339\n",
       "self                       261\n",
       "personal                   250\n",
       "private                    199\n",
       "self-employed              196\n",
       "independent                153\n",
       "individual                  75\n",
       "myself                      75\n",
       "freelance developer         63\n",
       "me                          62\n",
       "consultant                  50\n",
       "independent contractor      49\n",
       "freelance web developer     36\n",
       "web developer               33\n",
       "independent consultant      30\n",
       "software developer          29\n",
       "independent developer       28\n",
       "freelancing                 23\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#iteratively apply the list as a string search, and mark true where a match is found\n",
    "householdOutColumn=ossPyFuncs.addBooleanColumnFromCriteria(companyColumn,householdTermList,'household')\n",
    "\n",
    "print(str(np.count_nonzero(householdOutColumn['household'])) + ' household innovators found')\n",
    "\n",
    "subsetHouseholdUsers=householdOutColumn[householdOutColumn['household']]\n",
    "subsetHouseholdUsersCountDF=subsetHouseholdUsers['company'].value_counts()\n",
    "subsetHouseholdUsersCountDF.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a fairly sizable number.  Lets try this same approach again, but this time, instead of using a list of terms we generated, lets use an existing list of academic institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20772 academic contributors found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "carnegie mellon university           474\n",
       "university of washington             403\n",
       "stanford university                  395\n",
       "tsinghua university                  252\n",
       "columbia university                  246\n",
       "cornell university                   203\n",
       "university of waterloo               202\n",
       "zhejiang university                  195\n",
       "university of toronto                193\n",
       "imperial college london              182\n",
       "northeastern university              167\n",
       "university of oxford                 163\n",
       "new york university                  163\n",
       "duke university                      163\n",
       "university of cambridge              163\n",
       "peking university                    162\n",
       "university of southern california    161\n",
       "university of pennsylvania           159\n",
       "harvard university                   156\n",
       "johns hopkins university             153\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formulate sql query\n",
    "postgreSql_selectQuery=\"SELECT institution FROM hipolabs.universities ;\"\n",
    "#perform query\n",
    "universitiesList=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "universitiesList=pd.DataFrame(universitiesList['institution'].str.lower())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#use that query output for the iterative boolean vector creation\n",
    "universityOutColumn=ossPyFuncs.addBooleanColumnFromCriteria(companyColumn,universitiesList,'academic')\n",
    "\n",
    "#count the number of true\n",
    "print(str(np.count_nonzero(universityOutColumn['academic'])) + ' academic contributors found')\n",
    "\n",
    "subsetAcademicUsers=universityOutColumn[universityOutColumn['academic']]\n",
    "subsetAcademicUsersCountDF=subsetAcademicUsers['company'].value_counts()\n",
    "subsetAcademicUsersCountDF.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now lets do the same thing again but for government branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669 government contributors found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "oak ridge national laboratory                   54\n",
       "argonne national laboratory                     54\n",
       "los alamos national laboratory                  41\n",
       "lawrence livermore national laboratory          38\n",
       "sandia national laboratories                    34\n",
       "lawrence berkeley national laboratory           28\n",
       "brookhaven national laboratory                  19\n",
       "pacific northwest national laboratory           16\n",
       "lawrence livermore national laboratory, llnl    15\n",
       "slac national accelerator laboratory            13\n",
       "idaho national laboratory                       11\n",
       "fermi national accelerator laboratory           11\n",
       "tendermint                                      10\n",
       "consumer financial protection bureau             8\n",
       "us army                                          7\n",
       "paypermint                                       7\n",
       "national renewable energy laboratory             6\n",
       "minted                                           6\n",
       "imint                                            5\n",
       "fannie mae                                       4\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formulate sql query\n",
    "postgreSql_selectQuery=\"SELECT agency FROM us_gov_depts.us_gov_azindex ;\"\n",
    "#perform query\n",
    "govtList=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "govtList=pd.DataFrame(govtList['agency'].str.lower())\n",
    "govtList=pd.DataFrame('\\\\b'+govtList['agency']+'\\\\b')\n",
    "\n",
    "\n",
    "#use that query output for the iterative boolean vector creation\n",
    "governmentOutColumn=ossPyFuncs.addBooleanColumnFromCriteria(companyColumn,govtList,'government')\n",
    "\n",
    "#count the number of true\n",
    "print(str(np.count_nonzero(governmentOutColumn['government'])) + ' government contributors found')\n",
    "\n",
    "subsetGovernmentUsers=governmentOutColumn[governmentOutColumn['government']]\n",
    "subsetGovernmentUsersCountDF=subsetGovernmentUsers['company'].value_counts()\n",
    "subsetGovernmentUsersCountDF.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally lets try this for commercial entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35244 business contributors found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "microsoft              6363\n",
       "red hat                2063\n",
       "ibm                    1865\n",
       "facebook               1194\n",
       "intel                  1000\n",
       "alibaba                 677\n",
       "baidu                   562\n",
       "amazon                  547\n",
       "sap                     510\n",
       "shopify                 490\n",
       "oracle                  417\n",
       "uber                    395\n",
       "amazon web services     384\n",
       "vmware                  365\n",
       "apple                   354\n",
       "adobe                   331\n",
       "twitter                 315\n",
       "accenture               293\n",
       "netease                 276\n",
       "netflix                 259\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract multiple tables from the forbes dataset\n",
    "postgreSql_selectQuery=\"SELECT company FROM forbes.fortune2018_us1000 ;\"\n",
    "fortune2018=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "postgreSql_selectQuery=\"SELECT company FROM forbes.fortune2019_us1000 ;\"\n",
    "fortune2019=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "postgreSql_selectQuery=\"SELECT company FROM forbes.fortune2020_global2000 ;\"\n",
    "global2020=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#merge them together\n",
    "mergedCompanies=pd.concat([fortune2018,fortune2019,global2020],ignore_index=True)\n",
    "mergedCompanies=pd.DataFrame(mergedCompanies['company'].str.lower())\n",
    "mergedCompanies=pd.DataFrame('\\\\b'+mergedCompanies['company']+'\\\\b')\n",
    "\n",
    "#use that query output for the iterative boolean vector creation\n",
    "businessOutColumn=ossPyFuncs.addBooleanColumnFromCriteria(companyColumn,mergedCompanies,'business')\n",
    "\n",
    "#count the number of true\n",
    "print(str(np.count_nonzero(businessOutColumn['business'])) + ' business contributors found')\n",
    "\n",
    "subsetBusinessUsers=businessOutColumn[businessOutColumn['business']]\n",
    "subsetBusinessUsersCountDF=subsetBusinessUsers['company'].value_counts()\n",
    "subsetBusinessUsersCountDF.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this is a nontrivial number of people we've captured, it's still only a fraction of the 400 thousand plus users who have entered professional affiliations.  In the next notebook chapter, we'll look at a number of strategies for cleaning our input data to optimize our sectoring efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "microsoft                            6363\n",
       "red hat                              2063\n",
       "ibm                                  1865\n",
       "facebook                             1194\n",
       "intel                                1000\n",
       "alibaba                               677\n",
       "baidu                                 562\n",
       "amazon                                547\n",
       "sap                                   510\n",
       "shopify                               490\n",
       "carnegie mellon university            474\n",
       "oracle                                417\n",
       "uber                                  395\n",
       "amazon web services                   384\n",
       "vmware                                365\n",
       "apple                                 354\n",
       "adobe                                 331\n",
       "twitter                               315\n",
       "accenture                             293\n",
       "netease                               276\n",
       "netflix                               259\n",
       "zalando                               258\n",
       "atlassian                             238\n",
       "capgemini                             205\n",
       "cisco systems                         204\n",
       "university of toronto                 193\n",
       "nvidia                                192\n",
       "ebay                                  189\n",
       "ericsson                              173\n",
       "square                                173\n",
       "lyft                                  168\n",
       "autodesk                              165\n",
       "university of cambridge               163\n",
       "infosys                               162\n",
       "university of southern california     161\n",
       "paypal                                160\n",
       "@ amazon web services                 159\n",
       "naver                                 148\n",
       "nokia                                 146\n",
       "princeton university                  136\n",
       "orange                                136\n",
       "skyscanner                            129\n",
       "cerner                                124\n",
       "reaktor                               122\n",
       "samsung electronics                   117\n",
       "capital one                           116\n",
       "hewlett packard enterprise            116\n",
       "adobe systems                         114\n",
       "intuit                                114\n",
       "heroku                                113\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedCompanies.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
