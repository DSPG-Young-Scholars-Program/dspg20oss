{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of our overarching strategy for assigning users to specific sectors, we need to be able to assign users to business as well.  Given the specifics of our source dataset (GHTorrent), we can reasonably assume that the more frequently that a company name appears, the more \"authoratative\" (reflective of a consensus) of a representation of that company name it is.  Once we've removed the user entries that correspond to the non-business sectors, we can be reasonably confident in mapping users whose worplace affiliation listing is shared with some critical threshold of other users (i.e. 5) to the business sector.\n",
    "\n",
    "Lets begin by [obtaining the raw user data from the sql database](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/3a4431544bc32ac6abc82f14f8ccdd9f90923089/ossPy/ossPyFuncs.py#L9), as well as the user mappings for the acadmic and government sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "#assuming you're starting this notebook from it's source directory,\n",
    "#this will get us to the directory containing the ossPyFuncs library\n",
    "import ossPyFuncs\n",
    "\n",
    "#obtain the raw GHTorrent data\n",
    "postgreSql_selectQuery=\"SELECT login, company FROM gh.ctrs_raw ;\"\n",
    "fullData=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#perform sql query for academic entries\n",
    "postgreSql_selectQuery=\"SELECT login, company_cleaned, is_academic FROM gh.sna_ctr_academic ;\"\n",
    "academicCleaned=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#perform sql qery for government entries\n",
    "postgreSql_selectQuery=\"SELECT login, is_gov FROM gh.sna_ctr_gov ;\"\n",
    "govData=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#add nonprofit here and in the next code block if desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained those pre-exisitng user mappings, we need to join them into one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the academic into the raw table\n",
    "joinedData1=fullData.set_index('login').join(academicCleaned.set_index('login'))\n",
    "\n",
    "#join the government table into the raw/academic table\n",
    "joinedData2=joinedData1.join(govData.set_index('login'))\n",
    "\n",
    "#reset the the indexes\n",
    "joinedAndReset=joinedData2.reset_index()\n",
    "\n",
    "#it seems that the sql query pulls in boolean falses as NANs, which is not want we want for a boolean vector\n",
    "#as such, we replace the NANs in the relevant columns with false\n",
    "naReplaced=joinedAndReset[['is_gov','is_academic']].fillna(value=False)\n",
    "\n",
    "#take those NAN replaced columns and reinsert them\n",
    "fixedDataframe=joinedAndReset.assign(is_gov=naReplaced['is_gov'],is_academic=naReplaced['is_academic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform a full sectoring we also need the information for household and null values.  Lets obtain those now from our source keylists for [household](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/individualKeys.csv) and [null values](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/nullKeys.csv).  After that, we'll determine which users have yet to be mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#get the directory structure using the ossPyFuncs library as the reference point\n",
    "currentDir=os.path.dirname('ossPyFuncs.py')\n",
    "\n",
    "#obtain the household list from the keyfile directory, and make a bool column for it\n",
    "houseHoldList=pd.read_csv(os.path.join(currentDir,'keyFiles/individualKeys.csv'),quotechar=\"'\",header=None)\n",
    "withHouseholdColumn=ossPyFuncs.addBooleanColumnFromCriteria(fixedDataframe,houseHoldList,'household')\n",
    "\n",
    "#obtain the null list from the keyfile directory, and make a bool column for it\n",
    "noneList=pd.read_csv(os.path.join(currentDir,'keyFiles/nullKeys.csv'),quotechar=\"'\",header=None)\n",
    "withNoneColumn=ossPyFuncs.addBooleanColumnFromCriteria(withHouseholdColumn,noneList,'null')\n",
    "\n",
    "#generate a bool column for all users that have been mapped, these will be excluded from our business count\n",
    "alreadyAssigned=withNoneColumn[['is_gov','is_academic','household','null']].any(axis=1)\n",
    "\n",
    "#extract those users which are not assigned\n",
    "onlyUnassignedFrame=fixedDataframe.loc[~alreadyAssigned]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have derived the list of users which have yet to be assigned, lets clean their input in the company column, in preperation for subsequent processing.  We'll be cleaning out entries for substrings related to [legal entities](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/curatedLegalEntitesRaw.csv), [web domains](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/curatedDomains.csv), and [extraneous symbols](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/symbolRemove.csv) as [described in another notebook](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/Notebooks/Company%20Cleaning%20Narritive.ipynb) and [quantatively profiled in another](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/Notebooks/Cleaning%20heuristic%20assesment.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#construct path to legal entity list and erase them\n",
    "LElist=pd.read_csv(os.path.join(currentDir,'keyFiles/curatedLegalEntitesRaw.csv'),quotechar=\"'\",header=None)\n",
    "LEoutput, LEeraseList=ossPyFuncs.eraseFromColumn(onlyUnassignedFrame['company'],LElist)\n",
    "\n",
    "#construct path to legal symbol list and erase them\n",
    "symbollist=pd.read_csv(os.path.join(currentDir,'keyFiles/symbolRemove.csv'),quotechar=\"'\",header=None)\n",
    "Symboloutput, symbolEraseList=ossPyFuncs.eraseFromColumn(LEoutput,symbollist)\n",
    "#construct path to legal symbol list and erase them\n",
    "domainsList=pd.read_csv(os.path.join(currentDir,'keyFiles/curatedDomains.csv'),quotechar=\"'\",header=None)\n",
    "domiansOutput, domainsEraseList=ossPyFuncs.eraseFromColumn(Symboloutput,domainsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fully cleaned and remapped the data (and in doing so, collapsed redundant entries in to one another) we can now apply our heuristic count.  Specifically, given that we have removed all entries which would be associated with governmental, academic, and independent (household) users (and removed null entries), it seems reasonable to assume that entries which have multiple users listing them are businesses.  This inference is based on our exhausting any other workplace affiliations that a person might express.\n",
    "\n",
    "However, we have to apply a (somewhat arbitrary) cutoff when we decide the minimum number of users which have to list the same workplace in order for us to assume it reflects a valid business.  We'll begin with 5, but the code can be changed as one sees fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114015 users users assumed to be business sector, with 5 or more other users with the same listing\n"
     ]
    }
   ],
   "source": [
    "#set the threshold, change if you'd like\n",
    "threshold=5\n",
    "#get the column names\n",
    "domiansOutput=pd.DataFrame(domiansOutput)\n",
    "inputColumnName=domiansOutput.columns\n",
    "\n",
    "#get the counts from the cleaned column\n",
    "tableCleanedFullNameCounts=domiansOutput[inputColumnName[0]].value_counts()\n",
    "#convert that output to a proper table\n",
    "tableCleanedFullNameCounts=tableCleanedFullNameCounts.reset_index()\n",
    "#rename the columns\n",
    "tableCleanedFullNameCounts.rename(columns={inputColumnName[0]:\"count\",\"index\":inputColumnName[0]},inplace=True)\n",
    "\n",
    "\n",
    "#+1 because we are using greater than or equal to\n",
    "#we'll also be using this vector to obtain our user remapping\n",
    "aboveThresholdBoolVec=tableCleanedFullNameCounts['count'].ge(threshold+1)\n",
    "\n",
    "totalUsersAboveThreshold=np.sum(tableCleanedFullNameCounts['count'].loc[aboveThresholdBoolVec])\n",
    "\n",
    "print(str(totalUsersAboveThreshold)+ ' users users assumed to be business sector, with ' + str(threshold) + ' or more other users with the same listing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the raw count of the users meeting this criteria, we can also obtain a boolean vector that indicates which users are associated with these presumed businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PandasArray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8b69c2c30762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#may need to resort this in order to get it to line up with origional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msubjectIndexArray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msortedTableUniqueFullNameCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputIndexMapping'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maboveThresholdBoolVec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfullData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_business'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PandasArray' object is not callable"
     ]
    }
   ],
   "source": [
    "#we need to obtain the subject mapping to count, which we get via company affiliation.  We have a function for that.\n",
    "sortedInputColumn, sortedTableUniqueFullNameCounts=ossPyFuncs.uniquePandasIndexMapping(domiansOutput)\n",
    "    \n",
    "#may need to resort this in order to get it to line up with origional\n",
    "subjectIndexArray=sortedTableUniqueFullNameCounts['inputIndexMapping'].loc[aboveThresholdBoolVec].array()\n",
    "\n",
    "fullData['is_business']=False\n",
    "#somehow need to flatten, use np.ravel for this \n",
    "fullData['is_business'].loc[np.ravel(subjectIndexArray)]=True\n",
    "                            \n",
    "#this modified \"fullData\" object is now the desired ouput.  It can be joined with the entries in withNoneColumn\n",
    "#if one wishes for a complete output data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
