{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of our overarching strategy for assigning users to specific sectors, we need to be able to assign users to business as well.  Given the specifics of our source dataset (GHTorrent), we can reasonably assume that the more frequently that a company name appears, the more \"authoratative\" (reflective of a consensus) of a representation of that company name it is.  Once we've removed the user entries that correspond to the non-business sectors, we can be reasonably confident in mapping users whose worplace affiliation listing is shared with some critical threshold of other users (i.e. 5) to the business sector.\n",
    "\n",
    "Lets begin by [obtaining the raw user data from the sql database](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/3a4431544bc32ac6abc82f14f8ccdd9f90923089/ossPy/ossPyFuncs.py#L9), as well as the user mappings for the acadmic and government sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code guarentees you can impor the ossPyFuncs library\n",
    "import subprocess\n",
    "import os\n",
    "#get top directory path of the current git repository, under the presumption that\n",
    "#you're in the dspg20oss repo.\n",
    "gitRepoPath=subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('ascii').strip()\n",
    "#move to the osspy directory, assuming the directory structure has remained the  same\n",
    "os.chdir(os.path.join(gitRepoPath, 'ossPy'))\n",
    "#import the osspy library\n",
    "import ossPyFuncs\n",
    "\n",
    "#obtain the raw GHTorrent data\n",
    "postgreSql_selectQuery=\"SELECT login, company FROM gh.ctrs_raw ;\"\n",
    "fullData=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#perform sql query for academic entries\n",
    "postgreSql_selectQuery=\"SELECT login, company_cleaned, is_academic FROM gh.sna_ctr_academic ;\"\n",
    "academicCleaned=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "#perform sql qery for government entries\n",
    "postgreSql_selectQuery=\"SELECT login, is_gov FROM gh.sna_ctr_gov ;\"\n",
    "govData=ossPyFuncs.queryToPDTable(postgreSql_selectQuery)\n",
    "\n",
    "\n",
    "#add nonprofit here and in the next code block if desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained those pre-exisitng user mappings, we need to join them into one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40273 users with academic affiliations\n",
      "3576 users with governmental affiliations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>company</th>\n",
       "      <th>company_cleaned</th>\n",
       "      <th>is_academic</th>\n",
       "      <th>is_gov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0----0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0--key</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0-0-1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0-1-</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0-22</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0-3</td>\n",
       "      <td>Reborn Network</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0-60FPS</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0-8-15</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0-CNice</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     login         company company_cleaned is_academic  is_gov\n",
       "0        0            None                       False   False\n",
       "1   0----0            None                       False   False\n",
       "2   0--key            None                       False   False\n",
       "3    0-0-1            None                       False   False\n",
       "4     0-1-            None                       False   False\n",
       "5     0-22            None                       False   False\n",
       "6      0-3  Reborn Network                       False   False\n",
       "7  0-60FPS            None                       False   False\n",
       "8   0-8-15            None                       False   False\n",
       "9  0-CNice            None                       False   False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#join the academic into the raw table\n",
    "joinedData1=fullData.set_index('login').join(academicCleaned.set_index('login'))\n",
    "\n",
    "#join the government table into the raw/academic table\n",
    "joinedData2=joinedData1.join(govData.set_index('login'))\n",
    "\n",
    "#reset the the indexes\n",
    "joinedAndReset=joinedData2.reset_index()\n",
    "\n",
    "#it seems that pandas interpolates with NaN, which we have to reset to the relevant values for each column\n",
    "academicNanFix=pd.DataFrame(joinedAndReset['is_academic'].fillna(value=False))\n",
    "govNanFix=pd.DataFrame(joinedAndReset['is_gov'].fillna(value=False))\n",
    "companyCleanFix=pd.DataFrame(joinedAndReset['company_cleaned'].fillna(value=''))\n",
    "\n",
    "\n",
    "#get the count for both\n",
    "academicCount=np.count_nonzero(academicNanFix['is_academic'])\n",
    "print(str(academicCount) + ' users with academic affiliations')\n",
    "#get the count\n",
    "govCount=np.count_nonzero(govNanFix['is_gov'])\n",
    "print(str(govCount) + ' users with governmental affiliations')\n",
    "\n",
    "#take those NAN replaced columns and reinsert them\n",
    "fixedDataframe=joinedAndReset.assign(is_gov=govNanFix['is_gov'],is_academic=academicNanFix['is_academic'],company_cleaned=companyCleanFix['company_cleaned'])\n",
    "\n",
    "fixedDataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform a full sectoring we also need the information for household and null values.  Lets obtain those now from our source keylists for [household](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/individualKeys.csv) and [null values](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/nullKeys.csv).  After that, we'll determine which users have yet to be mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4715 users in individual sector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/2019.10-py3.7/lib/python3.7/site-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7819 users with null affiliations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#get the directory structure using the ossPyFuncs library as the reference point\n",
    "currentDir=os.path.dirname('ossPyFuncs.py')\n",
    "\n",
    "#obtain the household list from the keyfile directory, and make a bool column for it\n",
    "houseHoldList=pd.read_csv(os.path.join(currentDir,'keyFiles/individualKeys.csv'),quotechar=\"'\",header=None)\n",
    "withHouseholdColumn=ossPyFuncs.addBooleanColumnFromCriteria(pd.DataFrame(fixedDataframe['company']),houseHoldList,'household')\n",
    "#get the count\n",
    "householdCount=np.count_nonzero(withHouseholdColumn['household'])\n",
    "print(str(householdCount) + ' users in individual sector')\n",
    "#add the column to the main table\n",
    "fixedDataframe['household']=withHouseholdColumn['household']\n",
    "\n",
    "#obtain the null list from the keyfile directory, and make a bool column for it\n",
    "noneList=pd.read_csv(os.path.join(currentDir,'keyFiles/nullKeys.csv'),quotechar=\"'\",header=None)\n",
    "withNoneColumn=ossPyFuncs.addBooleanColumnFromCriteria(pd.DataFrame(fixedDataframe['company']),noneList,'null')\n",
    "#get the count\n",
    "nullCount=np.count_nonzero(withNoneColumn['null'])\n",
    "print(str(nullCount) + ' users with null affiliations')\n",
    "#add the column to the main table\n",
    "fixedDataframe['null']=withNoneColumn['null']\n",
    "\n",
    "#generate a bool column for all users that have been mapped, these will be excluded from our business count\n",
    "alreadyAssigned=fixedDataframe[['is_gov','is_academic','household','null']].any(axis=1)\n",
    "\n",
    "#extract those users which are not assigned\n",
    "onlyUnassignedFrame=fixedDataframe.loc[~alreadyAssigned]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have derived the list of users which have yet to be assigned, lets clean their input in the company column, in preperation for subsequent processing.  We'll be cleaning out entries for substrings related to [legal entities](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/curatedLegalEntitesRaw.csv), [web domains](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/curatedDomains.csv), and [extraneous symbols](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/keyFiles/symbolRemove.csv) as [described in another notebook](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/Notebooks/Company%20Cleaning%20Narritive.ipynb) and [quantatively profiled in another](https://github.com/DSPG-Young-Scholars-Program/dspg20oss/blob/master/ossPy/Notebooks/Cleaning%20heuristic%20assesment.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#construct path to legal entity list and erase them\n",
    "LElist=pd.read_csv(os.path.join(currentDir,'keyFiles/curatedLegalEntitesRaw.csv'),quotechar=\"'\",header=None)\n",
    "LEoutput, LEeraseList=ossPyFuncs.eraseFromColumn(onlyUnassignedFrame['company'],LElist)\n",
    "\n",
    "#construct path to legal symbol list and erase them\n",
    "symbollist=pd.read_csv(os.path.join(currentDir,'keyFiles/symbolRemove.csv'),quotechar=\"'\",header=None)\n",
    "Symboloutput, symbolEraseList=ossPyFuncs.eraseFromColumn(LEoutput,symbollist)\n",
    "#construct path to legal symbol list and erase them\n",
    "domainsList=pd.read_csv(os.path.join(currentDir,'keyFiles/curatedDomains.csv'),quotechar=\"'\",header=None)\n",
    "domiansOutput, domainsEraseList=ossPyFuncs.eraseFromColumn(Symboloutput,domainsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fully cleaned and remapped the data (and in doing so, collapsed redundant entries in to one another) we can now apply our heuristic count.  Specifically, given that we have removed all entries which would be associated with governmental, academic, and independent (household) users (and removed null entries), it seems reasonable to assume that entries which have multiple users listing them are businesses.  This inference is based on our exhausting any other workplace affiliations that a person might express.\n",
    "\n",
    "However, we have to apply a (somewhat arbitrary) cutoff when we decide the minimum number of users which have to list the same workplace in order for us to assume it reflects a valid business.  We'll begin with 5, but the code can be changed as one sees fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the threshold, change if you'd like\n",
    "threshold=5\n",
    "#get the column names\n",
    "domiansOutput=pd.DataFrame(domiansOutput)\n",
    "inputColumnName=domiansOutput.columns\n",
    "\n",
    "#get the counts from the cleaned column\n",
    "tableCleanedFullNameCounts=domiansOutput[inputColumnName[0]].value_counts()\n",
    "#convert that output to a proper table\n",
    "tableCleanedFullNameCounts=tableCleanedFullNameCounts.reset_index()\n",
    "#rename the columns\n",
    "tableCleanedFullNameCounts.rename(columns={inputColumnName[0]:\"count\",\"index\":inputColumnName[0]},inplace=True)\n",
    "\n",
    "\n",
    "#+1 because we are using greater than or equal to\n",
    "#we'll also be using this vector to obtain our user remapping\n",
    "aboveThresholdBoolVec=tableCleanedFullNameCounts['count'].ge(threshold+1)\n",
    "\n",
    "totalUsersAboveThreshold=np.sum(tableCleanedFullNameCounts['count'].loc[aboveThresholdBoolVec])\n",
    "\n",
    "print(str(totalUsersAboveThreshold)+ ' users users assumed to be business sector, with ' + str(threshold) + ' or more other users with the same listing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the raw count of the users meeting this criteria, we can also obtain a boolean vector that indicates which users are associated with these presumed businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force lowercase\n",
    "domiansOutput=domiansOutput.assign(company=domiansOutput['company'].str.lower())\n",
    "\n",
    "#we need to obtain the subject mapping to count, which we get via company affiliation.  We have a function for that.\n",
    "sortedInputColumn, sortedTableUniqueFullNameCounts=ossPyFuncs.uniquePandasIndexMapping(pd.DataFrame(domiansOutput))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting this out because previous cell takes a long time to run\n",
    "\n",
    "#reset the indexing alterations that occur with the previous function\n",
    "namesWithMapping=sortedTableUniqueFullNameCounts.set_index('index')\n",
    "namesWithMapping=namesWithMapping.sort_index()\n",
    "\n",
    "#drop the empty vector\n",
    "namesWithMapping=namesWithMapping[namesWithMapping.company != '']\n",
    "\n",
    "#may need to resort this in order to get it to line up with origional\n",
    "superThresholdIndexSubframe=namesWithMapping['inputIndexMapping'].loc[aboveThresholdBoolVec]\n",
    "\n",
    "#initialize concatonation vector\n",
    "concatIndexArray=np.ma.empty([1],dtype=int)\n",
    "print(concatIndexArray)\n",
    "#WARNING: this function generates an array that is NOT empty, but rather contains a -1 which will cause \n",
    "#signifigant problems when indexing if not dealt with.\n",
    "\n",
    "#iteratively concatonate the user indexes obtained from the remapping function\n",
    "for index, value in superThresholdIndexSubframe.iteritems():\n",
    "    concatIndexArray=np.concatenate([concatIndexArray,superThresholdIndexSubframe.loc[index].to_numpy()])\n",
    "\n",
    "#here we deal with the aformentioned [-1] issue by indexing all but the first numbers of the vector\n",
    "concatIndexArray= concatIndexArray[1:-1]   \n",
    "    \n",
    "fixedDataframe['is_business']=False\n",
    "fixedDataframe['is_business'].loc[concatIndexArray]=True\n",
    "fixedDataframe['company_cleaned']=domiansOutput\n",
    "\n",
    "fixedDataframe.head(10)\n",
    "#save down this object if you so choose, WARNING: it will be big\n",
    "fixedDataframe.to_csv('fixedDataFrame.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we round out this notebook we can make some final observations.  For example, we can look at the top 20 company affiliations on GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesWithMapping.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20=namesWithMapping.loc[0:20]\n",
    "import seaborn as sns\n",
    "ax=sns.barplot(x='count',y='company',data=top20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can create a barplot depiciting the counts for the various affiliations we have mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#establish new column\n",
    "fixedDataframe['AfiliationString']=''\n",
    "\n",
    "#set an appropriate string \n",
    "fixedDataframe['AfiliationString'].loc[fixedDataframe['is_business']]='Business'\n",
    "fixedDataframe['AfiliationString'].loc[fixedDataframe['is_gov']]='Government'\n",
    "fixedDataframe['AfiliationString'].loc[fixedDataframe['household']]='Individual'\n",
    "fixedDataframe['AfiliationString'].loc[fixedDataframe['is_academic']]='Academic'\n",
    "#label unmapped by process of elimination\n",
    "LabeledBoolVec=fixedDataframe[['is_gov','is_academic','household','is_business']].any(axis=1)\n",
    "#fixedDataframe['AfiliationString'].loc[np.logical_not(LabeledBoolVec)]='Unmapped'\n",
    "\n",
    "#for some reason we have to go back and relabel academic?\n",
    "fixedDataframe['AfiliationString'].loc[academicNanFix['is_academic']]='Academic'\n",
    "\n",
    "#and plot\n",
    "ax=sns.countplot(x='AfiliationString',data=fixedDataframe)\n",
    "ax.set_yscale(\"log\")\n",
    "plt.figure(figsize=(16,32),dpi=200)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(academicNanFix['is_academic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectorCounts=fixedDataframe['AfiliationString'].value_counts()\n",
    "sectorCounts.head(6)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
